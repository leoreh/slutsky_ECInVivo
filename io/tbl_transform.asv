function [tblOut, transParams] = tbl_transform(tbl, varargin)
% TBL_TRANSFORM Applies log/logit transformations, z-scoring, and normalization.
%
%   [TBLOUT, PARAMS] = TBL_TRANSFORM(TBL, ...) transforms table columns to
%   improve their distributional properties.
%
%   MODES:
%       1. FIT MODE: Calculates statistics (Mean, SD, Skewness) from TBL,
%          applies transformations, and returns the parameters in PARAMS.
%       2. APPLY MODE: Uses parameters from a previous run (passed via
%          'template') to transform TBL using those exact statistics.
%          Prevents data leakage between Training and Test sets.
%
%   INPUTS:
%       tbl         - (table) Input data table.
%       varargin    - (param/value) Optional parameters:
%
%           MODE SELECTION:
%           'template': (struct) Output PARAMS from a previous run. If
%                       provided, all other settings are IGNORED.
%
%           VARIABLE SELECTION (Fit Mode Only):
%           'varsInc' : (cell) Variables to transform {[]}. Overrides varsExc.
%           'varsExc' : (cell) Variables to exclude from transform {[]}.
%           'varsGrp' : (cell/char) Categorical variables defining groups for
%                       separate Z-scoring/Normalization {[]}.
%
%           TRANSFORMATION SETTINGS (Fit Mode Only):
%           'flgZ'    : (logical) Z-score variables {true}.
%           'logBase' : (mix) Transformation mode {[]}:
%                       - []/empty: No log.
%                       - 'logit': Logit transform log(y/(1-y)).
%                       - 'e': Natural Log transform log(y).
%                       - (numeric): Log transform with specific base.
%           'skewThr' : (numeric) Skewness threshold for auto-log {2}.
%           'flg0'    : (logical) Force offset for zero-values {false}.
%                       Note: Offset is auto-added if Log+Zeros detected.
%
%           NORMALIZATION (Fit Mode Only):
%           'varNorm' : (char) Grouping variable for normalization.
%                       Normalizes values relative to the mean of the first
%                       category (Reference).
%
%           MISC:
%           'verbose' : (logical) Print actions {false}.
%
%   OUTPUTS:
%       tblOut      - (table) Transformed table.
%       transParams - (struct) Structure containing applied settings and
%                     statistics, suitable for use as 'template'.
%
%   EXAMPLES:
%       % 1. FIT: Transform Training Data
%       [tblTrn, P] = tbl_transform(dataTrn, 'flgZ', true, 'logBase', 10);
%
%       % 2. APPLY: Transform Test Data (using Training stats)
%       tblTst = tbl_transform(dataTst, 'template', P);
%
%   See also: LME_ANALYSE, LME_ABLATION

%% ========================================================================
%  INPUT PARSING
%  ========================================================================

p = inputParser;
addRequired(p, 'tbl', @istable);

% Mode A: Apply Template
addParameter(p, 'template', [], @(x) isempty(x) || isstruct(x));

% Mode B: Fit New Parameters
addParameter(p, 'varsInc', [], @(x) iscell(x) || isempty(x));
addParameter(p, 'varsExc', [], @(x) iscell(x) || isempty(x));
addParameter(p, 'varsGrp', [], @(x) iscell(x) || ischar(x) || isstring(x) || isempty(x));
addParameter(p, 'flgZ', false, @islogical);
addParameter(p, 'logBase', [], @(x) isempty(x) || isnumeric(x) || ischar(x));
addParameter(p, 'skewThr', 2, @isnumeric);
addParameter(p, 'flg0', false, @islogical);
addParameter(p, 'varNorm', '', @ischar);
addParameter(p, 'verbose', false, @islogical);

parse(p, tbl, varargin{:});

tmpl = p.Results.template;
verbose = p.Results.verbose;


%% ========================================================================
%  ROUTE LOGIC (FIT vs APPLY)
%  ========================================================================

if ~isempty(tmpl)
    % --- APPLY MODE ---
    if verbose, fprintf('[TBL_TRANSFORM] Apply Mode: Using template stats.\n'); end
    [tblOut, transParams] = apply_transform(tbl, tmpl, verbose);
else
    % --- FIT MODE ---
    if verbose, fprintf('[TBL_TRANSFORM] Fit Mode: Calculating stats.\n'); end
    [tblOut, transParams] = fit_transform(tbl, p.Results);
end

end


%% ========================================================================
%  CORE: FIT PARAMETERS & TRANSFORM
%  ========================================================================
function [tblOut, params] = fit_transform(tbl, args)

% Parse Settings
varsInc = args.varsInc;
varsExc = args.varsExc;
varsGrp = args.varsGrp;
if ischar(varsGrp) || isstring(varsGrp)
    varsGrp = cellstr(varsGrp);
end

flgZ    = args.flgZ;
logBase = args.logBase;
skewThr = args.skewThr;
flg0    = args.flg0;
varNorm = args.varNorm;
verbose = args.verbose;

% Identify Variables
tblVars = tbl.Properties.VariableNames;
if ~isempty(varsInc)
    procVars = varsInc;
elseif ~isempty(varsExc)
    procVars = tblVars(~ismember(tblVars, varsExc));
else
    procVars = tblVars;
end

% Filter Numeric
isNum = cellfun(@(x) isnumeric(tbl.(x)) && ~iscategorical(tbl.(x)), procVars);
procVars = procVars(isNum);

% Normalization Ref
flgNorm = ~isempty(varNorm);
catRef = [];
if flgNorm
    if ismember(varNorm, varsGrp)
        error('varNorm "%s" cannot be included in varsGrp', varNorm);
    end
    cats = categories(tbl.(varNorm));
    catRef = cats{1}; % First category is reference
end
if flgNorm && flgZ
    warning('Z-scoring will overwrite normalization scale.');
end

% Output Structure
params = struct();
params.varsGrp = varsGrp;
params.varNorm = varNorm;
params.catRef  = catRef;
params.varList = struct(); % Stores individual var params
tblOut = tbl;

% Log Transformation Mode
isLogit = ischar(logBase) && strcmpi(logBase, 'logit');
isLog   = (isnumeric(logBase) && ~isempty(logBase)) || ...
    (ischar(logBase) && strcmpi(logBase, 'e'));
baseVal = [];
if isnumeric(logBase) && ~isempty(logBase)
    baseVal = logBase;
end

% Identify Groups
if ~isempty(varsGrp)
    [uGrps, ~, grpIdx] = unique(tblOut(:, varsGrp), 'rows');
else
    uGrps = table(); % Dummy for compatibility
    grpIdx = ones(height(tblOut), 1);
end

% Loop Variables
for iVar = 1:numel(procVars)
    var = procVars{iVar};
    data = tblOut.(var);

    % --- Determine Log/Offset (Global) ---
    doLog = false;
    doOffset = flg0;
    c = 0; % Offset value

    % Logit
    if isLogit
        data = max(eps, min(1-eps, data)); % Clamp
        data = log(data ./ (1 - data));
        if verbose, fprintf('[%s] Applied Logit.\n', var); end
    end

    % Log (Check Skewness)
    if isLog
        s = skewness(data(~isnan(data)));
        if s > skewThr
            doLog = true;
            doOffset = true; % E.g. Log(0) protection
            if verbose, fprintf('[%s] Skew %.2f > %.1f. Log enabled.\n', var, s, skewThr); end
        end
    end

    % Calculate Offset
    if doOffset
        if any(data(:) == 0) && all(data(:) >= 0)
            c = min(data(data > 0)) / 2; % Half of min non-zero
            data = data + c;
            if verbose, fprintf('[%s] Added Offset %.4f.\n', var, c); end
        end
    end

    % Apply Log
    if doLog
        if isempty(baseVal) % 'e'
            data = log(data);
        else
            data = log(data) ./ log(baseVal);
        end
    end

    % Update Table (Intermediate)
    tblOut.(var) = data;


    % --- Calculate Group Stats (Norm/Z) ---
    % Store stats in a table: [GroupVals, Mean, SD, RefMean]
    nGrps = max(grpIdx);
    stats = table();
    if ~isempty(varsGrp), stats = uGrps; end

    stats.Mean    = nan(nGrps, 1);
    stats.SD      = nan(nGrps, 1);
    stats.RefMean = nan(nGrps, 1);

    for iGrp = 1:nGrps
        idxK = (grpIdx == iGrp);
        vals = data(idxK);

        stats.Mean(iGrp) = mean(vals, 'omitnan');
        stats.SD(iGrp)   = std(vals, 'omitnan');

        if flgNorm
            % Find Reference Subgroup
            % Intersect Group K with Reference Category of varNorm
            idxRef = (tbl.(varNorm) == catRef);
            valsRef = data(idxK & idxRef);
            stats.RefMean(iGrp) = mean(valsRef, 'omitnan');
        end
    end

    % --- Apply Group Transformations ---
    for iGrp = 1:nGrps
        idxK = (grpIdx == iGrp);
        vals = tblOut.(var)(idxK); % Get current (possibly logged) data

        % Norm
        if flgNorm
            rm = stats.RefMean(iGrp);
            if ~isnan(rm) && rm ~= 0
                vals = 100 + ((vals - rm) / abs(rm) * 100);
            elseif rm == 0
                vals = 100 + vals; 
            end
        end

        % Z-Score
        if flgZ
            mu = stats.Mean(iGrp);
            sigma = stats.SD(iGrp);
            if sigma ~= 0
                vals = (vals - mu) / sigma;
            else
                vals = vals - mu; % Center only if const
            end
        end

        tblOut.(var)(idxK) = vals;
    end

    % Save Params for this var
    pVar = struct();
    pVar.isLogit  = isLogit;
    pVar.doLog    = doLog;
    pVar.logBase  = logBase; 
    pVar.offset   = c;
    pVar.flgNorm  = flgNorm;
    pVar.flgZ     = flgZ;
    pVar.stats    = stats;

    params.varList.(var) = pVar;
end

end


%% ========================================================================
%  CORE: APPLY TRANSFORMATION
%  ========================================================================
function [tblOut, params] = apply_transform(tbl, tmpl, verbose)

params = tmpl; % Return same params
tblOut = tbl;

varsGrp = tmpl.varsGrp;
varNorm = tmpl.varNorm;
catRef  = tmpl.catRef;

% Available vars in table
tblVars = tbl.Properties.VariableNames;

% Iterate through variables present in BOTH table and template
procVars = fieldnames(tmpl.varList);
procVars = procVars(ismember(procVars, tblVars));

% Match Groups
if ~isempty(varsGrp)

    % Pick the stats table from the first var to get group definitions
    pFirst = tmpl.varList.(procVars{1});
    uGrps  = pFirst.stats(:, varsGrp); % Just the keys

    % Map tbl rows to uGrps indices
    [~, idxGrp] = ismember(tblOut(:, varsGrp), uGrps, 'rows');

    % Handle missing groups (new groups in Test not seen in Train)
    % For now, warn and skip (or use NaN).
    if any(idxGrp == 0)
        warning('tbl_transform:NewGroups', ...
            '%d rows have groups not seen in Template. Results will be NaN.', ...
            sum(idxGrp==0));
    end
else
    idxGrp = ones(height(tblOut), 1);
end

% Apply
for iVar = 1:numel(procVars)
    var = procVars{iVar};
    pVar = tmpl.varList.(var);
    data = tblOut.(var);

    % Logit
    if pVar.isLogit
        data = max(eps, min(1-eps, data));
        data = log(data ./ (1 - data));
    end

    % Offset
    if pVar.offset > 0
        data = data + pVar.offset;
    end

    % Log
    if pVar.doLog
        baseVal = [];
        if isnumeric(pVar.logBase) && ~isempty(pVar.logBase), baseVal = pVar.logBase; end

        if isempty(baseVal)
            data = log(data);
        else
            data = log(data) ./ log(baseVal);
        end
    end

    % Update Global Transforms result
    tblOut.(var) = data;

    % Group Transforms (Norm/Z) via Lookup

    stats = pVar.stats;
    nStats = height(stats);

    vecMean = nan(height(tbl), 1);
    vecSD   = nan(height(tbl), 1);
    vecRef  = nan(height(tbl), 1);

    validRows = (idxGrp > 0);
    validIdx  = idxGrp(validRows);

    vecMean(validRows) = stats.Mean(validIdx);
    vecSD(validRows)   = stats.SD(validIdx);
    
    % Apply Norm
    if pVar.flgNorm
        vecRef(validRows) = stats.RefMean(validIdx);
        isOK = ~isnan(vecRef) & vecRef ~= 0;
        data(~isOK) = NaN;
        data(isOK) = 100 + ((data(isOK) - vecRef(isOK)) ./ abs(vecRef(isOK)) * 100);
    end

    % Apply Z
    if pVar.flgZ
        % data = (data - mu) / sigma
        isOK = ~isnan(vecMean) & ~isnan(vecSD);
        data(~isOK) = NaN;

        isConst = (vecSD == 0);
        data(isOK & ~isConst) = (data(isOK & ~isConst) - vecMean(isOK & ~isConst)) ./ vecSD(isOK & ~isConst);
        data(isOK & isConst)  = data(isOK & isConst) - vecMean(isOK & isConst);
    end

    tblOut.(var) = data;

    if verbose, fprintf('[%s] Applied Template Transform.\n', var); end
end

end

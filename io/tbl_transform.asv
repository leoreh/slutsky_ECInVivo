function [tblOut, transParams] = tbl_transform(tbl, varargin)
% TBL_TRANSFORM Applies log/logit transformations, z-scoring, and normalization.
%
%   [TBLOUT, PARAMS] = TBL_TRANSFORM(TBL, ...) transforms table columns to
%   improve their distributional properties for statistical modeling.
%
%   MODES:
%       1. FIT MODE: Calculates statistics (Mean, SD, Skewness, Reference)
%          from TBL, applies transformations, and returns the parameters in
%          PARAMS.
%       2. APPLY MODE: Uses parameters from a previous run (passed via
%          'template') to transform TBL using those exact statistics.
%          Prevents data leakage between Training and Test sets.
%       3. INVERSE MODE: Reverses the transformations to recover original values.
%
%   INPUTS:
%       tbl         - (table) Input data table.
%       varargin    - (param/value) Optional parameters:
%
%           MODE SELECTION:
%           'template': (struct) Output PARAMS from a previous run. If
%                       provided, the function runs in APPLY or INVERSE mode.
%           'flgInv'  : (logical) If true (and template provided), reverses
%                       transformations. {false}
%
%           VARIABLE SELECTION (Fit Mode Only):
%           'varsInc' : (cell) Variables to transform {[]}. Overrides varsExc.
%           'varsExc' : (cell) Variables to exclude from transform {[]}.
%           'varsGrp' : (cell/char) Categorical variables defining groups for
%                       separate Z-scoring/Normalization {[]}.
%
%           TRANSFORMATION SETTINGS (Fit Mode Only):
%           'flgZ'    : (logical) Z-score variables {true}.
%                       NOTE: If true, 'varNorm' is ignored (Conflict).
%           'logBase' : (mix) Transformation mode {[]}:
%                       - []/empty: No log.
%                       - 'logit': Logit transform log(y/(1-y)).
%                       - 'e': Natural Log transform log(y).
%                       - (numeric): Log transform with specific base.
%           'skewThr' : (numeric) Skewness threshold for auto-log {2}.
%           'flg0'    : (logical) Force offset for zero-values {false}.
%                       Note: Offset is auto-added if Log+Zeros detected.
%
%           NORMALIZATION (Fit Mode Only):
%           'varNorm' : (char) Grouping variable for normalization.
%                       Normalizes values relative to the mean of the first
%                       category (Reference). {''}
%
%           MISC:
%           'verbose' : (logical) Print actions {false}.
%
%   OUTPUTS:
%       tblOut      - (table) Transformed table.
%       transParams - (struct) Structure containing applied settings and
%                     statistics, suitable for use as 'template'.
%
%   EXAMPLES:
%       % 1. FIT: Transform Training Data
%       [tblTrn, P] = tbl_transform(dataTrn, 'flgZ', true, 'logBase', 10);
%
%       % 2. APPLY: Transform Test Data (using Training stats)
%       tblTst = tbl_transform(dataTst, 'template', P);
%
%       % 3. INVERSE: Recover Original Data
%       tblRec = tbl_transform(tblTst, 'template', P, 'flgInv', true);
%
%   See also: LME_ANALYSE, LME_ABLATION

%% ========================================================================
%  INPUT PARSING
%  ========================================================================

p = inputParser;
addRequired(p, 'tbl', @istable);

% Mode A: Apply Template
addParameter(p, 'template', [], @(x) isempty(x) || isstruct(x));

% Mode B: Fit New Parameters
addParameter(p, 'varsInc', [], @(x) iscell(x) || isempty(x));
addParameter(p, 'varsExc', [], @(x) iscell(x) || isempty(x));
addParameter(p, 'varsGrp', [], @(x) iscell(x) || ischar(x) || isstring(x) || isempty(x));
addParameter(p, 'flgZ', false, @islogical);
addParameter(p, 'logBase', [], @(x) isempty(x) || isnumeric(x) || ischar(x));
addParameter(p, 'skewThr', 2, @isnumeric);
addParameter(p, 'flg0', false, @islogical);
addParameter(p, 'varNorm', '', @ischar);
addParameter(p, 'verbose', false, @islogical);

% Mode C: Inverse Transform (Back to Original)
addParameter(p, 'flgInv', false, @islogical);

parse(p, tbl, varargin{:});

tmpl    = p.Results.template;
flgInv  = p.Results.flgInv;
verbose = p.Results.verbose;


%% ========================================================================
%  ROUTE LOGIC (FIT vs APPLY vs INVERSE)
%  ========================================================================

if isempty(tmpl)
    % --- FIT MODE ---
    if verbose, fprintf('[TBL_TRANSFORM] Fit Mode \n'); end
    [tblOut, transParams] = trans_fit(tbl, p.Results);
else
    if flgInv
        % --- INVERSE MODE ---
        if verbose, fprintf('[TBL_TRANSFORM] Inverse Mode \n'); end
        [tblOut, transParams] = trans_inv(tbl, tmpl, verbose);
    else
        % --- APPLY MODE ---
        if verbose, fprintf('[TBL_TRANSFORM] Apply Mode \n'); end
        [tblOut, transParams] = trans_apply(tbl, tmpl, verbose);
    end
end

end     % EOF


%% ========================================================================
%  CORE: FIT PARAMETERS & TRANSFORM
%  ========================================================================
function [tblOut, params] = trans_fit(tbl, args)

% Parse Settings
varsInc = args.varsInc;
varsExc = args.varsExc;
varsGrp = args.varsGrp;
if ischar(varsGrp) || isstring(varsGrp)
    varsGrp = cellstr(varsGrp);
end

flgZ    = args.flgZ;
logBase = args.logBase;
skewThr = args.skewThr;
flg0    = args.flg0;
varNorm = args.varNorm;
verbose = args.verbose;

% Conflict Resolution: Z-Score vs Norm
% If Z-scoring is requested, it overrides Normalization because they conflict
% (Z creates 0-mean unit-variance, Norm creates 100-mean relative scale).
if flgZ && ~isempty(varNorm)
    warning('tbl_transform:Conflict', 'Z-scoring is enabled. Normalization (varNorm) will be IGNORED.');
    varNorm = ''; % Disable Norm
end

% Identify Variables
tblVars = tbl.Properties.VariableNames;
if ~isempty(varsInc)
    procVars = varsInc;
elseif ~isempty(varsExc)
    procVars = tblVars(~ismember(tblVars, varsExc));
else
    procVars = tblVars;
end

% Filter Numeric
isNum = cellfun(@(x) isnumeric(tbl.(x)) && ~iscategorical(tbl.(x)), procVars);
procVars = procVars(isNum);

% Normalization Ref
flgNorm = ~isempty(varNorm);
catRef = [];
if flgNorm
    if ismember(varNorm, varsGrp)
        error('varNorm "%s" cannot be included in varsGrp', varNorm);
    end
    cats = categories(tbl.(varNorm));
    catRef = cats{1}; % First category is reference
end

% Output Structure
params = struct();
params.varsGrp = varsGrp;
params.varNorm = varNorm;
params.catRef  = catRef;
params.varList = struct(); % Stores individual var params
tblOut = tbl;

% Log Transformation Mode
isLogit = ischar(logBase) && strcmpi(logBase, 'logit');
isLog   = (isnumeric(logBase) && ~isempty(logBase)) || ...
    (ischar(logBase) && strcmpi(logBase, 'e'));
baseVal = [];
if isnumeric(logBase) && ~isempty(logBase)
    baseVal = logBase;
end

% Identify Groups (for Stats Calculation)
if ~isempty(varsGrp)
    [uGrps, ~, grpIdx] = unique(tblOut(:, varsGrp), 'rows');
else
    uGrps = table();
    grpIdx = ones(height(tblOut), 1);
end

% Process Each Variable
for iVar = 1:numel(procVars)
    var  = procVars{iVar};
    data = tblOut.(var);

    % --- 1. Determine Log/Offset Settings (Global) ---
    doLog = false;
    doOffset = flg0;
    c = 0; % Offset value

    % Logit Checks
    if isLogit
        % Clamp for stability but DON'T apply yet to check 0s?
        % Actually, if data is [0, 1], Logit needs clamping.
        data = max(eps, min(1-eps, data));
        data = log(data ./ (1 - data));
        if verbose, fprintf('[%s] Applied Logit.\n', var); end
    end

    % Log Checks (Skewness)
    if isLog
        s = skewness(data(~isnan(data)));
        if s > skewThr
            doLog = true;
            doOffset = true; % Check offset if log enabled
            if verbose, fprintf('[%s] Skew %.2f > %.1f. Log enabled.\n', var, s, skewThr); end
        end
    end

    % Calculate Offset (Before Log)
    if doOffset
        % Only add offset if there are zeros AND no negative values
        if any(data(:) == 0) && all(data(:) >= 0)
            c = min(data(data > 0)) / 2; % Half of min non-zero
            data = data + c;
            if verbose, fprintf('[%s] Added Offset %.4f.\n', var, c); end
        end
    end

    % Apply Log
    if doLog
        if isempty(baseVal) % 'e'
            data = log(data);
        else
            data = log(data) ./ log(baseVal);
        end
    end

    % Update Table (Transformation applied)
    tblOut.(var) = data;

    % --- 2. Calculate Statistics (Group-wise) ---
    % Calculate Mean/SD on the 'Intermediate' data (Logged/Offset).
    % If we Z-score, we use these stats.

    nGrps = max(grpIdx);
    stats = table();
    if ~isempty(varsGrp), stats = uGrps; end

    stats.Mean    = nan(nGrps, 1);
    stats.SD      = nan(nGrps, 1);
    stats.RefMean = nan(nGrps, 1);

    for iGrp = 1:nGrps
        idxK = (grpIdx == iGrp);
        vals = data(idxK);

        stats.Mean(iGrp) = mean(vals, 'omitnan');
        stats.SD(iGrp)   = std(vals, 'omitnan');

        if flgNorm
            % Find Reference Subgroup within this Group
            idxRef = (tbl.(varNorm) == catRef);
            valsRef = data(idxK & idxRef);
            stats.RefMean(iGrp) = mean(valsRef, 'omitnan');
        end
    end

    % --- 3. Apply Group Transformations (Z-Score OR Norm) ---
    % Note: Norm and Z are mutually exclusive due to earlier check.

    for iGrp = 1:nGrps
        idxK = (grpIdx == iGrp);
        vals = tblOut.(var)(idxK);

        % Normalization
        if flgNorm
            rm = stats.RefMean(iGrp);
            if ~isnan(rm) && rm ~= 0
                vals = 100 + ((vals - rm) / abs(rm) * 100);
            elseif rm == 0
                vals = 100 + vals;
            end
        end

        % Z-Score
        if flgZ
            mu = stats.Mean(iGrp);
            sigma = stats.SD(iGrp);

            % Handle constant columns
            if sigma ~= 0
                vals = (vals - mu) / sigma;
            else
                vals = vals - mu; % Center only if const
            end
        end

        tblOut.(var)(idxK) = vals;
    end

    % Save Parameters
    pVar = struct();
    pVar.isLogit  = isLogit;
    pVar.doLog    = doLog;
    pVar.logBase  = logBase;
    pVar.offset   = c;
    pVar.flgNorm  = flgNorm;
    pVar.flgZ     = flgZ;
    pVar.stats    = stats;

    params.varList.(var) = pVar;
end

end


%% ========================================================================
%  CORE: APPLY TRANSFORMATION
%  ========================================================================
function [tblOut, params] = trans_apply(tbl, tmpl, verbose)

params = tmpl; % Stats from template
tblOut = tbl;

% Match Groups
varsGrp = tmpl.varsGrp;
if ~isempty(varsGrp)
    fns = fieldnames(tmpl.varList);
    if isempty(fns)
        % Fallback if no variables were transformed?
        % We need uGrps to map groups. If no vars, we rely on implicit logic or return empty?
        % Actually, if no vars, we can't transform anything.
        % But we might still need to handle the table pass-through?
        % For now, error or fallback.
        warning('tbl_transform:NoVars', 'Template contains no variable parameters.');
        idxGrp = ones(height(tblOut), 1);
    else
        pFirst = tmpl.varList.(fns{1});
        uGrps  = pFirst.stats(:, varsGrp);

        [~, idxGrp] = ismember(tblOut(:, varsGrp), uGrps, 'rows');

        if any(idxGrp == 0)
            warning('tbl_transform:NewGroups', ...
                '%d rows have groups not seen in Template. Results will be NaN.', ...
                sum(idxGrp==0));
        end
    end
else
    idxGrp = ones(height(tblOut), 1);
end

% Process Vars
procVars = fieldnames(tmpl.varList);
procVars = procVars(ismember(procVars, tbl.Properties.VariableNames));

for iVar = 1:numel(procVars)
    var = procVars{iVar};
    pVar = tmpl.varList.(var);
    data = tblOut.(var);

    % --- 1. Global Transforms ---
    % Logit
    if pVar.isLogit
        data = max(eps, min(1-eps, data));
        data = log(data ./ (1 - data));
    end

    % Offset
    if pVar.offset > 0
        data = data + pVar.offset;
    end

    % Log
    if pVar.doLog
        baseVal = [];
        if isnumeric(pVar.logBase) && ~isempty(pVar.logBase), baseVal = pVar.logBase; end

        if isempty(baseVal)
            data = log(data);
        else
            data = log(data) ./ log(baseVal);
        end
    end

    % --- 2. Group Transforms ---
    stats = pVar.stats;

    vecMean = nan(height(tbl), 1);
    vecSD   = nan(height(tbl), 1);
    vecRef  = nan(height(tbl), 1);

    validRows = (idxGrp > 0);
    validIdx  = idxGrp(validRows);

    vecMean(validRows) = stats.Mean(validIdx);
    vecSD(validRows)   = stats.SD(validIdx);

    % Apply Norm
    if pVar.flgNorm
        vecRef(validRows) = stats.RefMean(validIdx);
        isOK = ~isnan(vecRef) & vecRef ~= 0;

        data(~isOK) = NaN;
        data(isOK)  = 100 + ((data(isOK) - vecRef(isOK)) ./ abs(vecRef(isOK)) * 100);
    end

    % Apply Z
    if pVar.flgZ
        isOK = ~isnan(vecMean) & ~isnan(vecSD);
        data(~isOK) = NaN;

        isConst = (vecSD == 0);
        data(isOK & ~isConst) = (data(isOK & ~isConst) - vecMean(isOK & ~isConst)) ./ vecSD(isOK & ~isConst);
        data(isOK & isConst)  = data(isOK & isConst) - vecMean(isOK & isConst);
    end

    tblOut.(var) = data;
end
end


%% ========================================================================
%  CORE: INVERSE TRANSFORM
%  ========================================================================
function [tblOut, params] = trans_inv(tbl, tmpl, verbose)

params = tmpl;
tblOut = tbl;

% Match Groups
varsGrp = tmpl.varsGrp;
tblVars = tbl.Properties.VariableNames;

if ~isempty(varsGrp) && all(ismember(varsGrp, tblVars))
    fns = fieldnames(tmpl.varList);
    if isempty(fns)
        warning('tbl_transform:NoVarsInv', 'Template contains no variable parameters.');
        idxGrp = ones(height(tblOut), 1);
    else
        pFirst = tmpl.varList.(fns{1});
        uGrps  = pFirst.stats(:, varsGrp);
        [~, idxGrp] = ismember(tblOut(:, varsGrp), uGrps, 'rows');

        if any(idxGrp == 0)
            warning('tbl_transform:UnknownGroups', 'Unknown groups in Inverse. Using default stats.');
            idxGrp(idxGrp==0) = 1;
        end
    end
else
    if ~isempty(varsGrp)
        warning('tbl_transform:MissingGroups', 'Grouping vars missing. Using default stats.');
    end
    idxGrp = ones(height(tblOut), 1);
end

% Process Vars
procVars = fieldnames(tmpl.varList);
procVars = procVars(ismember(procVars, tblVars));

for iVar = 1:numel(procVars)
    var = procVars{iVar};
    pVar = tmpl.varList.(var);
    data = tblOut.(var);

    stats = pVar.stats;
    vecMean = stats.Mean(idxGrp);
    vecSD   = stats.SD(idxGrp);

    % --- Step 1: Reverse Group Transforms (Z or Norm) ---

    % Reverse Z-Score
    if pVar.flgZ
        isConst = (vecSD == 0);
        data(~isConst) = data(~isConst) .* vecSD(~isConst) + vecMean(~isConst);
        data(isConst)  = data(isConst) + vecMean(isConst);
    end

    % Reverse Norm
    if pVar.flgNorm
        vecRef = stats.RefMean(idxGrp);
        isOK = ~isnan(vecRef) & vecRef ~= 0;
        isZero = (vecRef == 0);

        data(isOK)   = ((data(isOK) - 100) ./ 100 .* abs(vecRef(isOK))) + vecRef(isOK);
        data(isZero) = data(isZero) - 100;
        data(~isOK & ~isZero) = NaN;
    end

    % --- Step 2: Reverse Global Transforms ---

    % Reverse Log
    if pVar.doLog
        baseVal = [];
        if isnumeric(pVar.logBase) && ~isempty(pVar.logBase), baseVal = pVar.logBase; end

        if isempty(baseVal)
            data = exp(data);
        else
            data = baseVal .^ data;
        end
    end

    % Reverse Offset (Must happen after exp if forward was log(x+c))
    if pVar.offset > 0
        data = data - pVar.offset;
    end

    % Reverse Logit
    if pVar.isLogit
        % y = log(p / (1-p)) -> p = 1 / (1 + exp(-y))
        data = 1 ./ (1 + exp(-data));
    end

    tblOut.(var) = data;
    if verbose, fprintf('[%s] Applied Inverse Transform.\n', var); end
end

end

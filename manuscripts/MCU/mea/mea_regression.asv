
%% ========================================================================
%  LOAD AND PREP
%  ========================================================================

[tbl, xVec, basepaths, v] = mcu_tblMea(basepaths, v);

% tblGUI_xy(xVec, tbl);
% tblGUI_scatHist(tbl, 'xVar', 'bFrac', 'yVar', 'rcvTime', 'grpVar', 'Group');
% tblGUI_bar(tbl, 'yVar', 'bFrac', 'xVar', 'Group');
% tblGUI_raster(tbl, 'grpVar', 'Name', 'grpVal', 'ctrl1')


% -------------------------------------------------------------------------
% PREPS

tblLme = tbl;
tblLme.Genotype = tblLme.Group == "Control";

% Recovered units
idxUnits = tbl.uRcv;

% List of possible predictors
listPrdct = {'pertDepth', 'fr', 'bFrac', 'Group', '(1|Name)'};
listRspns = {'uRcv', 'rcvGain', 'rcvErr', 'rcvTime', 'spkDfct', 'rcvSlope', 'Genotype'};


%% ========================================================================
%  ABLATION
%  ========================================================================

nFolds = 4;
nReps = 4;

% Recovery Probability
varsFxd  = {'pertDepth', 'bFrac', 'fr', 'Group'};
frml = sprintf('uRcv ~ %s + (1|Name)', strjoin(varsFxd, ' + '));
res = lme_ablation(tblLme, frml, 'nFolds', nFolds, 'nReps', nReps);

% Steady-state firing
varsFxd  = {'pertDepth', 'bFrac', 'Group'};
frml = sprintf('frSs ~ %s + (1|Name)', strjoin(varsFxd, ' + '));
res = lme_ablation(tblLme, frml, 'nFolds', nFolds, 'nReps', nReps);

% Others
varsFxd  = {'pertDepth', 'fr', 'bFrac', 'Group'};
frml = sprintf('spkDfct ~ %s + (1|Name)', strjoin(varsFxd, ' + '));
res = lme_ablation(tblLme, frml, 'nFolds', nFolds, 'nReps', nReps);

% Predict Genotype
varsFxd  = {'pertDepth', 'bFrac', 'fr'};
frml = sprintf('Genotype ~ %s', strjoin(varsFxd, ' + '));
res = lme_ablation(tblLme, frml, 'nFolds', nFolds, 'nReps', nReps);




res = lme_mediation(tblLme, 'bFrac', 'Genotype', 'uRcv', '(1|Name)');



%% ========================================================================
%  NOTE: BROADCASTING (NETWORK)
%  ========================================================================
%  When analyzing unit-level responses (e.g., uRcv) influenced by network-
%  level properties (e.g., Dimensionality), data must be structured
%  hierarchically within the input table.
%
%  1. Implementation:
%     Each row represents a single unit. Network-level metrics are
%     duplicated for every unit belonging to that specific recording or
%     animal. The random effect term (1|Name) prevents "pseudoreplication"
%     by accounting for the non-independence of units within one culture.
%
%  2. Interaction of Scales:
%     This allows the model to test if unit-specific features (Firing Rate)
%     interact with network features (Dimensionality) to predict outcome.
%  ========================================================================

%% ========================================================================
%  NOTE: CONTINUOUS PREDICTOR SCALING
%  ========================================================================
%  Continuous predictors (e.g., fr, dimensionality) should typically be
%  standardized (Z-scored) before fitting in GLME.
%
%  1. Numerical Stability:
%     Prevents large-magnitude variables from dominating the gradient
%     descent during Maximum Likelihood Estimation.
%
%  2. Interpretability:
%     If predictors are Z-scored, the resulting coefficient (beta)
%     represents the change in log-odds per one standard deviation
%     increase in the predictor.
%
%  3. Centering:
%     Centering variables around the mean ensures that the intercept
%     represents the expected outcome at the average value of the data.
%  ========================================================================

%% ========================================================================
%  NOTE: RESPONSE VARIABLE TRANSFORMATION
%  ========================================================================
%  The decision to transform or Z-score the response variable (y) depends
%  strictly on the chosen distribution and link function.
%
%  1. Binary Response (Logistic/Binomial):
%     - DO NOT Z-score.
%     - The variable must remain binary (0 and 1).
%     - Transformation would break the Logit link function.
%
%  2. Continuous Response (Gaussian/Linear):
%     - Z-scoring is optional.
%     - Use to compare across modalities.
%     - Results in "standardized coefficients."
%
%  3. Interpretation Trade-off:
%     - Raw units: High biological meaning.
%     - Z-scored: High statistical comparability.
%
%  It is technically common to Z-score the PREDICTORS while leaving the
%  RESPONSE in its original units (or log-units).
%
%  Fixed Effects Interpretation:
%     - If x is Z-scored and y is raw:
%     - Beta = change in y-units per 1-SD change in x.
%  ========================================================================

%% ========================================================================
%  NOTE: LOG-NORMAL AND GAMMA TRANSFORMATIONS
%  ========================================================================
%  If your continuous response variable is heavily right-skewed (common in
%  firing rate distributions), a log-transform is preferred over Z-scoring.
%
%  1. Physiological Scaling:
%     - Neural firing often follows log-normal distributions.
%     - Transformation linearizes the multiplicative relationships.
%
%  2. Technical Requirement:
%     - Ensure no zero-values exist (see "Handling Zeros" note below).
%     - Log-transforming before Z-scoring is a common "best practice."
%  ========================================================================

%% ========================================================================
%  NOTE: DATA SPECIFICS
%  ========================================================================
%
% Insisted to use rcvGain and spkDfct on logarithm scale so they can be
% analyzed with fitlme. rcvTime (and MF) probably still needs glme.
%
% BslFr is positively correlated with recovery time (model and model free).
% This makes sense considering most units drop to zero, and thus despite
% normalizing the target value, it is still largely influenced by BslFr. A
% similar result is obtained for SpkDftc. Because of this, and because it
% does not predict uRcv, it is omitted from subsequent models.
%
% Recovery slope depends too much on the selected model (e.g. sigmoid vs.
% exponential).
%
% A discripency between model-based and model-free parameters is that in
% the latter there is no correlation between frBsl and pertDepth because
% many values are clamped to c. Hence pertDepth should only be from the
% model.
%
% Recovery time includes units that reached their threshold value but
% didn't manage to maintain it.
% 
% Predicting Genotype is only meaningful without the random effect of Name.
%  ========================================================================








%
% When transitioning from binary classification (recovered vs. not
% recovered) to continuous variables (e.g., firing rate magnitude or
% recovery time), the mathematical objective shifts from predicting a
% probability to minimizing a residual error. Metrics like Accuracy, ROC,
% and AUC are technically invalid for continuous data because there is no
% discrete "correct" or "incorrect" threshold. Instead, we utilize
% regression metrics that quantify the distance between the observed
% physiological data and the modelâ€™s predictions.
%
% ### Coefficient of Determination () and Explained Variance
%
% The primary metric for continuous response variables is , which
% represents the proportion of the total variance in your data (e.g.,
% variance in firing rates across all neurons) that is explained by your
% predictors. In the context of Mixed-Effects Models (), we distinguish
% between **Marginal **, which accounts only for fixed effects like
% genotype or dimensionality, and **Conditional **, which accounts for both
% fixed and random effects (e.g., the variance explained by the specific
% animal or culture).
%
% ### Error-Based Metrics: RMSE and MAE
%
% While  provides a relative measure of fit, error-based metrics provide an
% absolute measure in the original physiological units (e.g., Hz).
%
% * Root Mean Square Error (RMSE)
% * Mean Absolute Error (MAE)
% * Mean Squared Error (MSE)
% * Residual Sum of Squares (RSS)
%
% RMSE is particularly useful because it penalizes large outliers more
% heavily than MAE, making it a sensitive indicator of model failure in
% highly variable neural recordings. If your model predicts a firing rate
% of 10 Hz but the unit fires at 15 Hz, the RMSE quantifies that 5 Hz
% discrepancy across the entire dataset.
%
% ### Ablation Analysis via Delta
%
% The "Importance" or ablation analysis you implemented for binary data
% remains technically valid for continuous data by replacing "Accuracy"
% with "." To rank the importance of a predictor like `bFrac` or
% `pertDepth`, you calculate the ****. This is the difference between the
% of the full model and the  of a model where that specific predictor has
% been removed. A large  indicates that the variable is a critical driver
% of the physiological response, whereas a  near zero suggests the variable
% provides redundant information.
%
% ### Information Criteria: AIC and BIC
%
% For continuous models, scientists often supplement  with Information
% Criteria, such as the Akaike Information Criterion (AIC) or the Bayesian
% Information Criterion (BIC). These metrics evaluate the "quality" of the
% model by balancing the goodness of fit against the number of predictors
% used. Technically, these metrics penalize "overfitting"; if adding a new
% network metric (like dimensionality) does not significantly improve the
% fit, the AIC/BIC will increase, signaling that the simpler model is more
% biologically parsimonious.
%
% ### Standardized Coefficients as Effect Size
%
% In addition to global metrics, the **Standardized Beta Coefficient** ()
% serves as a practical measure of "accuracy" or impact for individual
% variables. When your predictors are Z-scored, the  value tells you
% exactly how many standard deviations the firing rate changes for every
% one-standard-deviation increase in the predictor. This allows you to
% directly compare the "strength" of different biological factors, even if
% they have different units (e.g., comparing the effect of "burst fraction"
% vs. "genotype").
%
% ### Summary of Differences
%
% | Metric Type | Binary (Classification) | Continuous (Regression) | | ---
% | --- | --- | | **Primary Metric** | Balanced Accuracy / AUC |
% (Marginal/Conditional) | | **Error Metric** | Log-Loss / Cross-Entropy |
% RMSE / MAE | | **Ablation Target** |  Accuracy |  | | **Visualization** |
% ROC / Confusion Matrix | Predicted vs. Observed Plot |


% Cross-Validation for Continuous PhysiologyFor continuous variables, we
% transition from calculating accuracy to calculating predictive error.
% When you apply your model to a test set, the predict function generates a
% numerical value (e.g., an expected firing rate in Hz) rather than a
% probability. We then compare these predicted values ($\hat{y}$) to the
% actual observed values ($y$) using metrics that quantify "distance"
% rather than "correctness."A critical metric in this context is the
% Predictive $R^2$ (sometimes denoted as $Q^2$). While a standard $R^2$
% tells you how well the model describes the data it has already seen
% (estimation), the Predictive $R^2$ tells you how much variance the model
% can explain in a completely new animal or culture (prediction). This is
% the "next level" of validation required for high-impact physiological
% manuscripts.Implementing Ablation for Continuous ResponsesYou can perform
% the exact same ablation analysis you used for binary recovery by
% substituting "Accuracy" with the Mean Squared Error (MSE) or Coefficient
% of Determination ($R^2$) calculated on the test set.Fit the Full
% Model.Predict on Test Set.Calculate $R^2_{test}$.Ablate one
% predictor.Recalculate $\Delta R^2_{test}$.This $\Delta R^2_{test}$ is the
% continuous equivalent of your $\Delta$ Accuracy. It identifies which
% biological feature provides the most unique information for determining
% the magnitude of a unit's firing rate recovery.